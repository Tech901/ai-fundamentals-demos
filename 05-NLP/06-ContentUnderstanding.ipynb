{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Content Understanding\n",
    "\n",
    "This notebook demonstrates how to use the Azure AI Content Understanding service\n",
    "in Foundry Tools. Content Understanding provides powerful capabilities for analyzing\n",
    "and extracting information from documents and images.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Set the following environment variables:\n",
    "- `FOUNDRY_CONTENT_UNDERSTANDING_ENDPOINT` - Azure AI Content Understanding service endpoint\n",
    "- `FOUNDRY_API_KEY` - API key for authentication\n",
    "- `FOUNDRY_REGION` - Region in which Foundry resources are provisioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Setup\n",
    "\n",
    "Configure the Azure AI Content Understanding API endpoint and authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.environ[\"FOUNDRY_CONTENT_UNDERSTANDING_ENDPOINT\"]\n",
    "api_key = os.environ[\"FOUNDRY_API_KEY\"]\n",
    "region = os.environ[\"FOUNDRY_REGION\"]\n",
    "\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": api_key,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "console = Console()\n",
    "\n",
    "print(f\"API Endpoint: {endpoint}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(\"API Key: [CONFIGURED]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capability 1: List Content Analyzers\n",
    "\n",
    "The Content Understanding service provides various prebuilt analyzers for different\n",
    "document and image analysis tasks. Let's discover what analyzers are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available content analyzers\n",
    "list_url = f\"{endpoint}/contentunderstanding/analyzers?api-version=2025-11-01\"\n",
    "\n",
    "response = requests.get(list_url, headers=headers, timeout=30)\n",
    "response.raise_for_status()\n",
    "analyzers_result = response.json()\n",
    "\n",
    "print(\"API call successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw API Results - Available Analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(analyzers_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-Friendly Results - Available Analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "# Create a table of available analyzers\n",
    "table = Table(title=\"Available Content Analyzers\")\n",
    "table.add_column(\"Analyzer ID\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Description\", style=\"white\")\n",
    "\n",
    "for analyzer in analyzers_result.get(\"value\", []):\n",
    "    analyzer_id = analyzer.get(\"analyzerId\", \"N/A\")\n",
    "    description = analyzer.get(\"description\", \"No description available\")\n",
    "    table.add_row(analyzer_id, description)\n",
    "\n",
    "console.print(table)\n",
    "console.print(f\"\\n[bold green]Total Analyzers Available: {len(analyzers_result.get('value', []))}[/bold green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capability 2: Content Extraction\n",
    "\n",
    "Extract annotations and highlights from a PDF document using the prebuilt-layout analyzer.\n",
    "This is useful for extracting marked content, comments, and highlighted sections from documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare PDF Analysis Request\n",
    "\n",
    "We'll analyze a PDF ebook that contains highlights using the prebuilt-layout analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF URL with highlights\n",
    "pdf_url = \"https://www.dropbox.com/scl/fi/405z56tds3tewycemxp23/Azure-AI-Fundamentals-AI-900-Study-Guide-1.pdf?rlkey=i0t4xnrrt392lba4s4fqlt1j7&st=yomn8xte&dl=1\"\n",
    "\n",
    "# Download the PDF file\n",
    "print(f\"Downloading PDF from: {pdf_url}\")\n",
    "pdf_response = requests.get(pdf_url, timeout=60)\n",
    "pdf_response.raise_for_status()\n",
    "pdf_data = pdf_response.content\n",
    "print(f\"Downloaded {len(pdf_data)} bytes\")\n",
    "\n",
    "# Endpoint for binary content analysis\n",
    "analyze_url = f\"{endpoint}/contentunderstanding/analyzers/prebuilt-layout:analyzeBinary?api-version=2025-11-01&features=annotations\"\n",
    "\n",
    "# Prepare headers for binary upload\n",
    "pdf_headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": api_key,\n",
    "    \"Content-Type\": \"application/pdf\",\n",
    "}\n",
    "\n",
    "print(\"\\nAnalyzer: prebuilt-layout\")\n",
    "print(\"Features: annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make PDF Analysis API Call\n",
    "\n",
    "Submit the document for analysis. This is an asynchronous operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the analysis request with binary data\n",
    "response = requests.post(analyze_url, headers=pdf_headers, data=pdf_data, timeout=30)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Get the operation location to poll for results\n",
    "operation_location = response.headers.get(\"Operation-Location\")\n",
    "\n",
    "# Poll for results with progress bar\n",
    "max_attempts = 30\n",
    "pdf_result = None\n",
    "final_status = None\n",
    "\n",
    "for attempt in tqdm(range(max_attempts), desc=\"Polling for results\", unit=\"attempt\"):\n",
    "    time.sleep(2)\n",
    "    \n",
    "    result_response = requests.get(operation_location, headers=headers, timeout=30)\n",
    "    result_response.raise_for_status()\n",
    "    pdf_result = result_response.json()\n",
    "    \n",
    "    final_status = pdf_result.get(\"status\", \"\").lower()\n",
    "    \n",
    "    if final_status in [\"succeeded\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "# Print final status after progress bar completes\n",
    "if final_status == \"succeeded\":\n",
    "    print(\"\\n✓ Analysis completed successfully!\")\n",
    "elif final_status == \"failed\":\n",
    "    print(\"\\n✗ Analysis failed!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Timeout waiting for results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw API Results - PDF Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as pprint\n",
    "print(pdf_result['result'].keys())  # What is this thing?\n",
    "print(pdf_result['result']['contents'][0].keys()) # What's in the resulting \"contents\"?\n",
    "print(len(pdf_result['result']['contents'][0][\"annotations\"])) # How many annotations are there?\n",
    "pprint(pdf_result['result']['contents'][0][\"annotations\"][:10]) # How many annotations are there?\n",
    "\n",
    "# with open(\"06-pdf-results.txt\", \"w\") as f:\n",
    "#     f.write(pdf_result['result']['contents'])\n",
    "#     print('content written...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-Friendly Results - PDF Annotations\n",
    "\n",
    "Extract and display the highlighted content and annotations from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "if pdf_result.get(\"status\", \"\").lower() == \"succeeded\":\n",
    "    result = pdf_result.get(\"result\", {})\n",
    "    contents = result.get(\"contents\", [])\n",
    "    \n",
    "    # Extract annotations from contents\n",
    "    annotations = []\n",
    "    for content in contents:\n",
    "        for annotation in content.get(\"annotations\", []):\n",
    "            annotations.append({\n",
    "                \"id\": annotation.get(\"id\", \"Unknown\"),\n",
    "                \"kind\": annotation.get(\"kind\", \"Unknown\"),\n",
    "                \"author\": annotation.get(\"author\", \"\"),\n",
    "                \"createdAt\": annotation.get(\"createdAt\", \"\")\n",
    "            })\n",
    "    \n",
    "    # Display annotations in a table\n",
    "    if annotations:\n",
    "        table = Table(title=\"PDF Annotations & Highlights\")\n",
    "        table.add_column(\"ID\", style=\"cyan\")\n",
    "        table.add_column(\"Type\", style=\"yellow\")\n",
    "        table.add_column(\"Author\", style=\"green\")\n",
    "        table.add_column(\"Created At\", style=\"white\")\n",
    "        \n",
    "        for ann in annotations:\n",
    "            table.add_row(\n",
    "                ann[\"id\"],\n",
    "                ann[\"kind\"],\n",
    "                ann[\"author\"],\n",
    "                ann[\"createdAt\"]\n",
    "            )\n",
    "        \n",
    "        console.print(table)\n",
    "        console.print(f\"\\n[bold green]Total Annotations Found: {len(annotations)}[/bold green]\")\n",
    "    else:\n",
    "        console.print(\"[yellow]No annotations found in the document[/yellow]\")\n",
    "    \n",
    "    # Display document statistics\n",
    "    stats_table = Table(title=\"Document Statistics\")\n",
    "    stats_table.add_column(\"Metric\", style=\"cyan\")\n",
    "    stats_table.add_column(\"Value\", style=\"green\")\n",
    "    \n",
    "    stats_table.add_row(\"Total Contents\", str(len(contents)))\n",
    "    stats_table.add_row(\"Total Annotations\", str(len(annotations)))\n",
    "    \n",
    "    console.print(\"\\n\")\n",
    "    console.print(stats_table)\n",
    "else:\n",
    "    console.print(f\"[red]Analysis status: {pdf_result.get('status', 'Unknown')}[/red]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capability 3: Image Analysis\n",
    "\n",
    "Analyze images using the `prebuilt-imageSearch` analyzer & a gpt model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Model Defaults\n",
    "\n",
    "Before using image analyzers like `prebuilt-imageSearch`, we need to configure the default model deployments.\n",
    "This maps the model names used by the analyzers to your actual Azure AI Foundry deployment names.\n",
    "\n",
    "**Required models:**\n",
    "- `gpt-4.1` - For most prebuilt analyzers\n",
    "- `gpt-4.1-mini` - For RAG analyzers (documentSearch, imageSearch, audioSearch, videoSearch)\n",
    "- `text-embedding-3-large` - For embedding operations\n",
    "\n",
    "> **Note:** Update the deployment names in the cell below to match your actual Azure AI Foundry deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model deployment defaults for Content Understanding\n",
    "# This is required for prebuilt analyzers like prebuilt-imageSearch\n",
    "defaults_url = f\"{endpoint}contentunderstanding/defaults?api-version=2025-11-01\"\n",
    "\n",
    "# First, check current defaults\n",
    "response = requests.get(defaults_url, headers=headers, timeout=30)\n",
    "print(\"Current defaults:\")\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "# Configure the model deployments\n",
    "# You need to update these deployment names to match your actual Azure AI Foundry deployments\n",
    "model_config = {\n",
    "    \"modelDeployments\": {\n",
    "        \"gpt-4.1\": \"gpt-4.1\",  # Update with your GPT-4.1 deployment name\n",
    "        \"gpt-4.1-mini\": \"gpt-4.1-mini\",  # Update with your GPT-4.1-mini deployment name\n",
    "        \"text-embedding-3-large\": \"text-embedding-3-large\"  # Update with your embedding deployment name\n",
    "    }\n",
    "}\n",
    "\n",
    "patch_headers = headers.copy()\n",
    "patch_headers[\"Content-Type\"] = \"application/merge-patch+json\"\n",
    "\n",
    "response = requests.patch(defaults_url, headers=patch_headers, json=model_config, timeout=30)\n",
    "\n",
    "if response.ok:\n",
    "    print(\"\\n✓ Defaults configured successfully!\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "else:\n",
    "    print(f\"\\n✗ Failed to configure defaults: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Image 1: Produce\n",
    "\n",
    "Analyze our \"box of produce\" image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image of produce\n",
    "produce_image_url = \"https://images.unsplash.com/photo-1635341083777-5f93a755e916?q=80&w=500\"\n",
    "\n",
    "# Download the image\n",
    "image_response = requests.get(produce_image_url, timeout=30)\n",
    "image_response.raise_for_status()\n",
    "produce_image_data = image_response.content\n",
    "\n",
    "print(f\"Downloaded produce image: {len(produce_image_data)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the produce image\n",
    "# Note: Using prebuilt-imageSearch which provides image descriptions\n",
    "image_analyze_url = f\"{endpoint}contentunderstanding/analyzers/prebuilt-imageSearch:analyzeBinary?api-version=2025-11-01\"\n",
    "\n",
    "image_headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": api_key,\n",
    "    \"Content-Type\": \"application/octet-stream\",\n",
    "}\n",
    "\n",
    "response = requests.post(image_analyze_url, headers=image_headers, data=produce_image_data, timeout=30)\n",
    "\n",
    "# Check for errors and print detailed response\n",
    "if not response.ok:\n",
    "    print(f\"Error {response.status_code}: {response.reason}\")\n",
    "    print(f\"Response body: {response.text}\")\n",
    "    response.raise_for_status()\n",
    "\n",
    "# Get the operation location\n",
    "operation_location = response.headers.get(\"Operation-Location\")\n",
    "\n",
    "# Poll for results with progress bar\n",
    "max_attempts = 30\n",
    "produce_result = None\n",
    "final_status = None\n",
    "\n",
    "for attempt in tqdm(range(max_attempts), desc=\"Polling for results\", unit=\"attempt\"):\n",
    "    time.sleep(2)\n",
    "    \n",
    "    result_response = requests.get(operation_location, headers=headers, timeout=30)\n",
    "    result_response.raise_for_status()\n",
    "    produce_result = result_response.json()\n",
    "    \n",
    "    final_status = produce_result.get(\"status\", \"\").lower()\n",
    "    \n",
    "    if final_status in [\"succeeded\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "# Print final status after progress bar completes\n",
    "if final_status == \"succeeded\":\n",
    "    print(\"\\n✓ Analysis completed successfully!\")\n",
    "elif final_status == \"failed\":\n",
    "    print(\"\\n✗ Analysis failed!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Timeout waiting for results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw API Results - Produce Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(produce_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-Friendly Results - Produce Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "console = Console()\n",
    "\n",
    "if produce_result.get(\"status\") == \"Succeeded\":\n",
    "    result = produce_result.get(\"result\", {})\n",
    "    contents = result.get(\"contents\", [])\n",
    "    \n",
    "    console.print(Panel(\"[bold cyan]Produce Image Analysis[/bold cyan]\", expand=False))\n",
    "    \n",
    "    # Display the analyzed image\n",
    "    console.print(\"\\n[bold green]Analyzed Image:[/bold green]\")\n",
    "    display(IPImage(data=produce_image_data, width=400))\n",
    "    \n",
    "    # Extract and display the summary from fields\n",
    "    if contents:\n",
    "        content = contents[0]\n",
    "        fields = content.get(\"fields\", {})\n",
    "        \n",
    "        # Display Summary\n",
    "        summary_field = fields.get(\"Summary\", {})\n",
    "        summary_text = summary_field.get(\"valueString\", \"No summary available\")\n",
    "        \n",
    "        console.print(\"\\n[bold green]AI-Generated Summary:[/bold green]\")\n",
    "        console.print(Panel(summary_text, border_style=\"green\"))\n",
    "        \n",
    "        # Display metadata\n",
    "        stats_table = Table(title=\"Image Analysis Details\")\n",
    "        stats_table.add_column(\"Property\", style=\"cyan\")\n",
    "        stats_table.add_column(\"Value\", style=\"green\")\n",
    "        \n",
    "        stats_table.add_row(\"Analyzer\", content.get(\"analyzerId\", \"N/A\"))\n",
    "        stats_table.add_row(\"MIME Type\", content.get(\"mimeType\", \"N/A\"))\n",
    "        stats_table.add_row(\"Content Kind\", content.get(\"kind\", \"N/A\"))\n",
    "        \n",
    "        console.print(\"\\n\")\n",
    "        console.print(stats_table)\n",
    "    else:\n",
    "        console.print(\"[yellow]No content items found in the result[/yellow]\")\n",
    "else:\n",
    "    console.print(f\"[red]Analysis status: {produce_result.get('status', 'Unknown')}[/red]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Image 2: Elephants\n",
    "\n",
    "Analyze an image containing elephants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image of elephants\n",
    "elephants_image_url = \"https://images.unsplash.com/photo-1505148230895-d9a785a555fa?q=80&w=500\"\n",
    "\n",
    "# Download the image\n",
    "image_response = requests.get(elephants_image_url, timeout=30)\n",
    "image_response.raise_for_status()\n",
    "elephants_image_data = image_response.content\n",
    "\n",
    "print(f\"Downloaded elephants image: {len(elephants_image_data)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the elephants image\n",
    "image_analyze_url = f\"{endpoint}contentunderstanding/analyzers/prebuilt-imageSearch:analyzeBinary?api-version=2025-11-01\"\n",
    "response = requests.post(image_analyze_url, headers=image_headers, data=elephants_image_data, timeout=30)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Get the operation location\n",
    "operation_location = response.headers.get(\"Operation-Location\")\n",
    "\n",
    "# Poll for results with progress bar\n",
    "max_attempts = 30\n",
    "elephants_result = None\n",
    "final_status = None\n",
    "\n",
    "for attempt in tqdm(range(max_attempts), desc=\"Polling for results\", unit=\"attempt\"):\n",
    "    time.sleep(2)\n",
    "    \n",
    "    result_response = requests.get(operation_location, headers=headers, timeout=30)\n",
    "    result_response.raise_for_status()\n",
    "    elephants_result = result_response.json()\n",
    "    \n",
    "    final_status = elephants_result.get(\"status\", \"\").lower()\n",
    "    \n",
    "    if final_status in [\"succeeded\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "# Print final status after progress bar completes\n",
    "if final_status == \"succeeded\":\n",
    "    print(\"\\n✓ Analysis completed successfully!\")\n",
    "elif final_status == \"failed\":\n",
    "    print(\"\\n✗ Analysis failed!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Timeout waiting for results\")\n",
    "print(f\"Operation Location: {operation_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw API Results - Elephants Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(elephants_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-Friendly Results - Elephants Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "if elephants_result.get(\"status\", \"\").lower() == \"succeeded\":\n",
    "    result = elephants_result.get(\"result\", {})\n",
    "    contents = result.get(\"contents\", [])\n",
    "    \n",
    "    console.print(Panel(\"[bold cyan]Elephants Image Analysis[/bold cyan]\", expand=False))\n",
    "    \n",
    "    # Display the analyzed image\n",
    "    console.print(\"\\n[bold green]Analyzed Image:[/bold green]\")\n",
    "    display(IPImage(data=elephants_image_data, width=400))\n",
    "    \n",
    "    # Extract and display the summary from fields\n",
    "    if contents:\n",
    "        content = contents[0]\n",
    "        fields = content.get(\"fields\", {})\n",
    "        \n",
    "        # Display Summary\n",
    "        summary_field = fields.get(\"Summary\", {})\n",
    "        summary_text = summary_field.get(\"valueString\", \"No summary available\")\n",
    "        \n",
    "        console.print(\"\\n[bold green]AI-Generated Summary:[/bold green]\")\n",
    "        console.print(Panel(summary_text, border_style=\"green\"))\n",
    "        \n",
    "        # Display metadata\n",
    "        stats_table = Table(title=\"Image Analysis Details\")\n",
    "        stats_table.add_column(\"Property\", style=\"cyan\")\n",
    "        stats_table.add_column(\"Value\", style=\"green\")\n",
    "        \n",
    "        stats_table.add_row(\"Analyzer\", content.get(\"analyzerId\", \"N/A\"))\n",
    "        stats_table.add_row(\"MIME Type\", content.get(\"mimeType\", \"N/A\"))\n",
    "        stats_table.add_row(\"Content Kind\", content.get(\"kind\", \"N/A\"))\n",
    "        \n",
    "        console.print(\"\\n\")\n",
    "        console.print(stats_table)\n",
    "    else:\n",
    "        console.print(\"[yellow]No content items found in the result[/yellow]\")\n",
    "else:\n",
    "    console.print(f\"[red]Analysis status: {elephants_result.get('status', 'Unknown')}[/red]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook demonstrated three key capabilities of Azure AI Content Understanding:\n",
    "\n",
    "1. **Content Analyzers Discovery** - Listed all available prebuilt analyzers\n",
    "2. **Content Extraction** - Extracted annotations and highlights from a PDF document\n",
    "3. **Image Classification & Segmentation** - Analyzed and classified objects in images\n",
    "\n",
    "These capabilities can be used for various document and image analysis tasks including:\n",
    "- Document layout analysis\n",
    "- Annotation extraction\n",
    "- Object detection and classification\n",
    "- Image segmentation\n",
    "- Content understanding and categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
